{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ナイーブベイズ分類器\n",
    "\n",
    "ナイーブベイズ分類器(単純ベイズ分類器)は、名前の通りベイズの定理を分類問題に利用する。\n",
    "「ナイーブ」という名前がつけられた理由はベイズの定理を用いるために「全ての特徴量は互いに独立である」という仮定が必要になるから。\n",
    "現実の問題ではその過程が成立することは稀。しかしこの仮定によって計算量を簡素化・削減し、高速な上に、そこそこ優れた性能を示すことが多くある。\n",
    "\n",
    "またナイーブベイズは出力と関係ない特徴量にロバスト(無関係な特徴量はうまいこと無視してくれる)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learnのナイーブベイズ分類器\n",
    "\n",
    "ナイーブベイズ分類器は `sklearn.naive_bayes` パッケージにある。\n",
    "このパッケージには3つのナイーブベイズ分類器が存在。\n",
    "\n",
    "- GaussianNB: 特徴量は正規分布に従って分布すると仮定。例:「人の身長と体重が与えられた時に、その人の性別を分類する」\n",
    "- MultinomialNB: ある事象が発生した回数を特徴量としていると仮定。実際にこの分類器はTF-IDFと相性がよく、うまく分類出来るケースが多くあることが知られている。\n",
    "- BernoulliNB: MultinomialNBと少しにているが、単語の回数ではなく、単語が出現した/出現していないの2値で特徴量が表される場合に最適"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 感情分析(Sentiment Analysis)\n",
    "\n",
    "ある意見がポジティブかネガティブかを予測。\n",
    "今回は英語のデータセットである「Polarity Dataset v2.0」を使用。\n",
    "このデータセットにはPositive, Negativeそれぞれ1000件ずつ含まれている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import mixture\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_files = glob.glob('./txt_sentoken/pos/cv*.txt')\n",
    "neg_files = glob.glob('./txt_sentoken/neg/cv*.txt')\n",
    "text_list = []\n",
    "target = []\n",
    "\n",
    "for file in pos_files[:300]:\n",
    "    with open(file, \"r\") as file:\n",
    "        text_list.append(file.read())\n",
    "        target.append('pos')\n",
    "\n",
    "\n",
    "for file in neg_files[:300]:\n",
    "    with open(file, \"r\") as file:\n",
    "        text_list.append(file.read())\n",
    "        target.append('neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 英語をストップワードに追加。1単語 or 2単語を用いてベクトル化\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "X = vectorizer.fit_transform(text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validation.cross_val_score(clf, X.toarray(), np.array(target))\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
